# main.py
from langchain_community.retrievers import TavilySearchAPIRetriever
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI
from pydantic import BaseModel
from enum import Enum

from dotenv import load_dotenv
load_dotenv()

# =========================
# â‘  ãƒ¢ãƒ‡ãƒ«è¨­å®š
# =========================
model = ChatOpenAI(model="gpt-4o-mini")

# =========================
# â‘¡ Retrieverã®æº–å‚™
# =========================
langchain_document_retriever = TavilySearchAPIRetriever(k=3).with_config({
    "run_name": "langchain_document_retriever"
})
web_retriever = TavilySearchAPIRetriever(
    k=3,
    search_depth="advanced"
    ).with_config({
    "run_name": "web_retriever"
})

# =========================
# â‘¢ Routeå®šç¾©
# =========================
class Route(str, Enum):
    langchain_document = "langchain_document"
    web = "web"

class RouteOutput(BaseModel):
    route: Route

# =========================
# â‘£ Retrieveré¸æŠç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
# =========================
route_prompt = ChatPromptTemplate.from_template("""
æ¬¡ã®è³ªå•ã«å¯¾ã—ã¦ã€ã©ã®Retrieverã‚’ä½¿ã†ã¹ãã‹ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚
é¸æŠè‚¢ã¯ "langchain_document" ã¾ãŸã¯ "web" ã®ã„ãšã‚Œã‹ã§ã™ã€‚
å‡ºåŠ›ã¯ JSONå½¢å¼ã«ã—ã¦ãã ã•ã„ã€‚

è³ªå•: {question}
""")

# =========================
# â‘¤ route_chainï¼ˆãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼‰
# =========================
route_chain = (
    route_prompt
    | model.with_structured_output(RouteOutput)
    | (lambda x: x.route)
)

# =========================
# â‘¥ Retrieveråˆ‡æ›¿é–¢æ•°
# =========================
def routed_retriever(route, question):
    """ãƒ«ãƒ¼ãƒˆã«å¿œã˜ã¦é©åˆ‡ãªRetrieverã‚’å®Ÿè¡Œ"""
    if route == Route.langchain_document:
        return langchain_document_retriever.invoke(question)
    elif route == Route.web:
        return web_retriever.invoke(question)
    else:
        raise ValueError(f"Unknown route: {route}")

# =========================
# â‘¦ å›ç­”ç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
# =========================
prompt = ChatPromptTemplate.from_template("""
ã‚ãªãŸã¯å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
æ¬¡ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚‚ã¨ã«ã€è³ªå•ã«å¯¾ã—ã¦ç°¡æ½”ã§ã‚ã‹ã‚Šã‚„ã™ãå›ç­”ã—ã¦ãã ã•ã„ã€‚

ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:
{context}

è³ªå•:
{question}
""")

# =========================
# â‘§ å…¨ä½“ã®Chain
# =========================
route_rag_chain = (
    {
        "question": RunnablePassthrough(),
        "route": route_chain,
    }
    | RunnablePassthrough.assign(context=lambda x: routed_retriever(x["route"], x["question"]))
    | prompt
    | model
    | StrOutputParser()
)

# =========================
# â‘¨ ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
# =========================
if __name__ == "__main__":
    print("=== RAG Chatbot (qã§çµ‚äº†) ===\n")
    while True:
        question = input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆqã§çµ‚äº†ï¼‰: ").strip()
        if question.lower() == "q":
            print("çµ‚äº†ã—ã¾ã™ã€‚")
            break
        try:
            result = route_rag_chain.invoke({"question": question})
            print("\nğŸ§  å›ç­”:")
            print(result)
            print("-" * 50)
        except Exception as e:
            print(f"âš ï¸ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            print("-" * 50)
